import { useState, useEffect } from 'react';
import CodeBlock from './CodeBlock';
import TabbedCodeBlock from './TabbedCodeBlock';

interface CodeTab {
  filename: string;
  code: string;
  language?: string;
}

interface SlideProps {
  title: string;
  content?: string[];
  code?: string;
  codeTabs?: CodeTab[];
  note?: string;
}

function Slide({ title, content, code, codeTabs, note }: SlideProps) {
  return (
    <div className="w-full h-full flex flex-col justify-start px-12 md:px-16 lg:px-20 py-8 md:py-12 overflow-y-auto">
      <div className="max-w-7xl mx-auto w-full space-y-8 flex-1 flex flex-col">
        {/* Title - Always present */}
        <div className="text-center mb-8">
          <h1 className="text-4xl md:text-5xl lg:text-6xl font-bold text-white leading-tight tracking-tight">
            {title}
          </h1>
        </div>
        
        {/* Content area - flexible */}
        <div className="flex-1 flex flex-col justify-center space-y-8">
          {/* Content bullets */}
          {content && content.length > 0 && (
            <div className="w-full">
              <ul className="space-y-6 max-w-5xl mx-auto">
                {content.map((item, index) => (
                  <li key={index} className="flex items-start">
                    <div className="flex-shrink-0 w-8 flex justify-center">
                      <span className="text-blue-400 text-2xl font-bold mt-1">â€¢</span>
                    </div>
                    <span className="text-xl md:text-2xl text-gray-200 leading-relaxed ml-4 flex-1">
                      {item}
                    </span>
                  </li>
                ))}
              </ul>
            </div>
          )}
          
          {/* Tabbed code blocks or single code block */}
          {codeTabs && codeTabs.length > 0 ? (
            <div className="w-full flex justify-center">
              <div className="w-full max-w-6xl">
                <TabbedCodeBlock tabs={codeTabs} title="Implementation" />
              </div>
            </div>
          ) : code ? (
            <div className="w-full flex justify-center">
              <div className="w-full max-w-6xl">
                <CodeBlock 
                  code={code} 
                  language="python" 
                  title={title.includes("LangGraph") ? "LangGraph Implementation" : 
                         title.includes("MCP") ? "MCP Integration Example" :
                         title.includes("Debug") ? "LLM Debugging Prompt" : 
                         "Python Code"}
                />
              </div>
            </div>
          ) : null}
        </div>
        
        {/* Note - Always at bottom if present */}
        {note && (
          <div className="mt-auto pt-8">
            <p className="text-lg md:text-xl text-gray-400 italic text-center px-8 py-4 bg-gray-800/30 rounded-lg max-w-4xl mx-auto">
              {note}
            </p>
          </div>
        )}
      </div>
    </div>
  );
}

export default function SlideDeck() {
  const [currentSlide, setCurrentSlide] = useState(0);

  const slides: SlideProps[] = [
    // Slide 1 â€” Title & Setup
    {
      title: "Lessons Learned Building Agent & Agentic Developer Tooling",
      content: [
        "Everyday GenAI usage for devs",
        "Agents vs autocomplete & accountability", 
        "Graphs vs ReAct",
        "Example flow: Prompt â†’ Intent â†’ RAG or CI/CD",
        "Pitfalls, best practices, and debugging"
      ],
      note: "10-15 min talk â€¢ Use â†/â†’ to navigate"
    },
    
    // Slide 2 â€” Everyday GenAI + Interactive Opener
    {
      title: "Everyday GenAI + Interactive Opener",
      content: [
        "ðŸ‘‹ Who's built an agent? For DevEx? With MCP?",
        "Beyond autocomplete: user stories, interviews, research, docs",
        "Why agents matter for developer workflows",
        "Moving from single completions to multi-step reasoning"
      ],
      code: `# Simple prompt template for non-coding tasks
RESEARCH_PROMPT = """
You are a technical research assistant. 

Task: {task}
Context: {context}

Steps:
1. Search relevant documentation
2. Summarize key findings  
3. Provide actionable recommendations

Format your response with clear sections and citations.
"""`,
      note: "Agents excel at multi-step developer workflows"
    },
    
    // Slide 3 â€” Agents vs Autocomplete & Graphs vs ReAct  
    {
      title: "Agents vs Autocomplete & Graphs vs ReAct",
      content: [
        "Autocomplete: single predictions vs Agents: multi-step reasoning",
        "Senior vs junior usage patterns â€¢ Shared accountability",
        "ReAct loops: Think â†’ Act â†’ Observe â†’ Repeat (great for exploration)",
        "State Graphs: explicit nodes & edges, typed state, deterministic routing",
        "Rule: graphs for reliable workflows, ReAct for ad-hoc exploration"
      ],
      note: "Graphs provide reliability and observability for production workflows"
    },
    
    // Slide 4 â€” From Prompt to Intent
    {
      title: "From Prompt to Intent",
      codeTabs: [
        {
          filename: "prompt_intake.py",
          code: `from typing import TypedDict
from pydantic import BaseModel

class TaskState(TypedDict):
    user_prompt: str
    intent: Optional[str]
    context: Dict[str, Any]
    route: Optional[str]
    result: Optional[str]

class PromptInput(BaseModel):
    prompt: str
    user_context: Dict[str, Any]

async def intake_node(state: TaskState) -> TaskState:
    """Initial prompt processing and context gathering."""
    
    # Clean and structure the user input
    prompt = state["user_prompt"].strip()
    
    # Gather relevant context (user, repo, recent activity)
    context = {
        "user_id": state.get("user_id"),
        "repo_context": await get_repo_context(),
        "recent_tasks": await get_recent_tasks(),
        "timestamp": datetime.now().isoformat()
    }
    
    state["context"] = context
    state["logs"] = [f"Processed prompt: {prompt[:50]}..."]
    
    return state`,
          language: "python"
        },
        {
          filename: "intent_classifier.py", 
          code: `INTENT_CLASSIFIER_PROMPT = """
You are an intent classifier for developer workflows.

Given a user prompt, classify it into one of these intents:

1. **research** - Questions, documentation lookup, "how does X work?"
2. **implement** - Code changes, new features, bug fixes
3. **review** - Code review, analysis, security audit
4. **debug** - Troubleshooting, error investigation
5. **deploy** - CI/CD, deployment, infrastructure

User prompt: {prompt}
Context: {context}

Respond with:
- intent: <one of the above>
- confidence: <0.0 to 1.0>
- reasoning: <brief explanation>
- suggested_route: <rag|cicd|hybrid>

Format as JSON.
"""

async def classify_intent_node(state: TaskState) -> TaskState:
    """LLM classifies user intent to determine workflow path."""
    
    response = await llm.ainvoke([{
        "role": "user", 
        "content": INTENT_CLASSIFIER_PROMPT.format(
            prompt=state["user_prompt"],
            context=state["context"]
        )
    }])
    
    intent_data = json.loads(response.content)
    state["intent"] = intent_data["intent"]
    state["route"] = intent_data["suggested_route"]
    
    return state`,
          language: "python"
        },
        {
          filename: "router.py",
          code: `def route_guard(state: TaskState) -> str:
    """Deterministic routing based on classified intent."""
    
    intent = state.get("intent")
    route = state.get("route")
    
    # High-confidence routing
    if intent in ["research", "debug"] and route == "rag":
        return "rag_path"
    
    if intent in ["implement", "deploy"] and route == "cicd":
        return "cicd_path"
    
    if intent == "review" and route == "hybrid":
        return "hybrid_path"
    
    # Fallback for low confidence
    if not intent or not route:
        return "clarification_needed"
    
    # Default to RAG for unknown cases
    return "rag_path"

# Add to workflow
workflow.add_conditional_edges(
    "classify_intent",
    route_guard,
    {
        "rag_path": "rag_search",
        "cicd_path": "plan_implementation", 
        "hybrid_path": "parallel_branch",
        "clarification_needed": "ask_clarification"
    }
)`,
          language: "python"
        }
      ],
      note: "Intent classification â†’ deterministic routing prevents infinite loops"
    },
    
    // Slide 5 â€” RAG Path
    {
      title: "RAG Path: Search â†’ Ground â†’ Synthesize",
      codeTabs: [
        {
          filename: "mcp_search.py",
          code: `from typing import List
from pydantic import BaseModel

class SearchDocsInput(BaseModel):
    query: str
    filters: Dict[str, Any]

class DocumentChunk(BaseModel):
    doc_id: str
    content: str
    metadata: Dict[str, Any]
    score: float

async def mcp_search_docs(input: SearchDocsInput) -> List[DocumentChunk]:
    """Search internal knowledge base via MCP transport."""
    
    # Call MCP server for document search
    mcp_result = await mcp_client.call_tool(
        "search_knowledge_base",
        {
            "query": input.query,
            "limit": 10,
            "filters": input.filters
        }
    )
    
    # Convert to structured format
    chunks = [
        DocumentChunk(
            doc_id=doc["id"],
            content=doc["content"],
            metadata=doc["metadata"], 
            score=doc["relevance_score"]
        )
        for doc in mcp_result["documents"]
    ]
    
    return chunks`,
          language: "python"
        },
        {
          filename: "rag_state.py",
          code: `async def rag_search_node(state: TaskState) -> TaskState:
    """Search docs and update state with relevant context."""
    
    # Extract search query from user prompt  
    search_input = SearchDocsInput(
        query=state["user_prompt"],
        filters={"recent": True, "verified": True}
    )
    
    # Search via MCP
    doc_chunks = await mcp_search_docs(search_input)
    
    # Update state with search results
    state["search_results"] = [
        {
            "doc_id": chunk.doc_id,
            "snippet": chunk.content[:200] + "...",
            "score": chunk.score,
            "source": chunk.metadata.get("source", "unknown")
        }
        for chunk in doc_chunks
    ]
    
    state["logs"].append(f"Found {len(doc_chunks)} relevant documents")
    
    return state`,
          language: "python"
        },
        {
          filename: "synthesis.py", 
          code: `SYNTHESIS_PROMPT = """
You are a helpful technical assistant with access to internal documentation.

User Question: {user_prompt}

Relevant Documentation:
{doc_snippets}

Instructions:
1. Answer the user's question using ONLY the provided documentation
2. Include specific citations using [doc:ID] format
3. If information is incomplete, clearly state limitations
4. Provide actionable next steps when possible

Response format:
## Answer
[Your response here]

## Sources
- [doc:ID] Brief description of source

## Next Steps  
[If applicable]
"""

async def synthesize_answer_node(state: TaskState) -> TaskState:
    """Generate grounded answer with citations."""
    
    # Format search results for prompt
    doc_snippets = "\\n\\n".join([
        f"[doc:{result['doc_id']}] {result['snippet']}"
        for result in state["search_results"]
    ])
    
    # Generate answer
    response = await llm.ainvoke([{
        "role": "user",
        "content": SYNTHESIS_PROMPT.format(
            user_prompt=state["user_prompt"],
            doc_snippets=doc_snippets
        )
    }])
    
    state["result"] = response.content
    state["logs"].append("Generated grounded response with citations")
    
    return state`,
          language: "python"
        }
      ],
      note: "RAG path: search â†’ ground â†’ synthesize with citations"
    },
    
    // Slide 6 â€” CI/CD Path
    {
      title: "CI/CD Path: Plan â†’ Implement â†’ Test â†’ Deploy",
      codeTabs: [
        {
          filename: "state.py",
          code: `# pip install langgraph langchain_openai pydantic rich
from typing import TypedDict, Optional, List
from pydantic import BaseModel
from langgraph.graph import StateGraph, START, END
from langgraph.checkpoint.memory import MemorySaver

class DevState(TypedDict):
    task: str
    plan: List[str]
    code_patch: Optional[str]
    test_results: Optional[str]
    pr_url: Optional[str]
    logs: List[str]
    error: Optional[str]`,
          language: "python"
        },
        {
          filename: "tools.py", 
          code: `from langchain_core.tools import tool
from langgraph.prebuilt import ToolNode
from pydantic import BaseModel

class PlanInput(BaseModel):
    task: str

class CodeInput(BaseModel):
    spec: str
    plan: List[str]

@tool
def plan_task(input: PlanInput) -> List[str]:
    """Plan development task into actionable steps."""
    return ["analyze", "implement", "test", "propose_pr"]

@tool
def generate_code(input: CodeInput) -> str:
    """Generate code patch from specification."""
    return "// Generated patch content..."

@tool
def run_tests(code_patch: str) -> str:
    """Run tests on code patch."""
    return "OK: 124 tests; 0 failed"

@tool
def create_pr(code_patch: str) -> str:
    """Create pull request from code patch."""
    return "https://github.com/org/repo/pull/123"

# Create tool node for LangGraph
tools = [plan_task, generate_code, run_tests, create_pr]
tool_node = ToolNode(tools)`,
          language: "python"
        },
        {
          filename: "planner.py",
          code: `# Planner prompt for LLM tool selection
PLANNER_PROMPT = """
You are an expert development planning agent. Your job is to:

1. ANALYZE the task and current state
2. CHOOSE the right tool to call next
3. PROVIDE clear reasoning for your choice

Available tools:
- plan_task: Break down high-level task into steps
- generate_code: Create code from specification  
- run_tests: Execute tests on code changes
- create_pr: Open pull request with changes

Current state: {state}

INSTRUCTIONS:
- If no plan exists, call plan_task first
- If plan exists but no code, call generate_code  
- If code exists but no tests, call run_tests
- If tests pass, call create_pr
- If any step fails, explain the error and suggest retry/fix

Think step by step:
1. What is the current state?
2. What is the next logical step?
3. Which tool accomplishes that step?
4. What input does that tool need?

Call the appropriate tool with proper input.
"""`,
          language: "python"
        },
        {
          filename: "graph.py",
          code: `from langgraph.graph import StateGraph, START, END
from langchain_openai import ChatOpenAI

# LLM for planning decisions
llm = ChatOpenAI(model="gpt-4", temperature=0)

async def planner_node(state: DevState) -> DevState:
    """LLM chooses which tool to call based on current state."""
    
    # Format current state for LLM
    state_summary = {
        "task": state["task"],
        "has_plan": bool(state.get("plan")),
        "has_code": bool(state.get("code_patch")), 
        "has_tests": bool(state.get("test_results")),
        "error": state.get("error")
    }
    
    # Get LLM decision on next tool
    prompt = PLANNER_PROMPT.format(state=state_summary)
    response = await llm.ainvoke([{"role": "user", "content": prompt}])
    
    # Parse tool call from response
    # LLM will call appropriate tool via function calling
    state["logs"].append(f"Planner decision: {response.content}")
    return state

# Build the graph
workflow = StateGraph(DevState)
workflow.add_node("planner", planner_node)
workflow.add_node("tools", tool_node)  # ToolNode handles all tools

workflow.add_edge(START, "planner")
workflow.add_edge("planner", "tools")
workflow.add_edge("tools", "planner")  # Loop back for next decision

# Guard function to determine when to end
def should_continue(state: DevState) -> str:
    if state.get("pr_url"):
        return "end"
    if state.get("error"):
        return "end"  # Could retry instead
    return "continue"

workflow.add_conditional_edges(
    "planner", 
    should_continue, 
    {"continue": "tools", "end": END}
)

app = workflow.compile(checkpointer=MemorySaver())`,
          language: "python"
        }
      ],
      note: "Highlights: LLM planner â€¢ ToolNode integration â€¢ typed state â€¢ guarded loops"
    },
    {
      title: "MCP / RAG Integration (Sketch â€¢ Python)",
      code: `from typing import List
from pydantic import BaseModel

class SearchDocsInput(BaseModel):
    query: str

async def mcp_search_docs(input: SearchDocsInput) -> List[str]:
    """Search internal KB (RAG source) and return doc IDs (pure function)."""
    # call MCP transport -> tool "search_kb"
    return ["doc:abc", "doc:def"]

async def node_research(state: DevState) -> DevState:
    ids = await mcp_search_docs(SearchDocsInput(query=state["task"]))
    state["logs"].append(f"Research IDs: {ids}")
    return state

# To insert research before implement:
# workflow.add_node("research", node_research)
# workflow.add_edge("plan", "research")  
# workflow.add_edge("research", "implement")`,
      note: "Prefer pure, idempotent tools; isolate side effects behind explicit nodes"
    },
    {
      title: "Debugging State Graphs with LLMs",
      content: [
        "Structured logs make routing bugs and ReAct-style loops visible",
        "Ask LLMs to find: missing guards, non-idempotent tools, flaky steps",
        "Redact secrets; keep logs JSONL/NDJSON for easy pasting"
      ],
      code: `You are an expert in agentic state machines (LangGraph) and tool reliability.
Given the execution log, identify: (1) nodes that should be guarded, 
(2) non-idempotent tools, (3) missing termination conditions, 
(4) slow/flaky steps, and (5) concrete routing or retry policies to add.
Return a prioritized fix list with code-level changes.

<LOG>
{paste NDJSON log here}
</LOG>`
    },
    {
      title: "30-sec Tour: Bigger Graph (CI/CD Hygiene)",
      content: [
        "plan â†’ research â†’ implement â†’ test â†’ security_scan â†’ pr â†’ review_gate â†’ merge â†’ deploy_canary â†’ verify â†’ rollback_or_promote",
        "If security_scan fails â†’ suggest remediations; loop to implement (cap N)",
        "review_gate enforces human approval; verify checks SLOs; failures rollback"
      ]
    },
    {
      title: "Agents vs Autocomplete â€¢ Accountability",
      content: [
        "Fully agentic (AMP Code-style) vs non-agentic copilots",
        "Senior vs junior usage patterns; guardrails to prevent overreliance", 
        "Shared accountability: humans own merges; agents propose changes",
        "Universal fits: tests, debugging, refactoring"
      ]
    },
    {
      title: "Getting Started in < 1 Day",
      content: [
        "Pick one workflow (e.g., generate tests & open PR)",
        "Define 3â€“5 nodes + a TypedDict state",
        "Add budgets & guards; log everything", 
        "Wrap one MCP tool (RAG search or repo diff) and iterate with LLM-assisted debugging"
      ]
    },
    {
      title: "Close / CTA",
      content: [
        "Start small â€¢ Make it observable â€¢ Keep humans in the loop",
        "Agents that improve developer experience return value fastest",
        "Let agents help you build agents â€” bootstrap with prompts"
      ],
      note: "Thank you! Questions?"
    }
  ];

  const nextSlide = () => {
    setCurrentSlide((prev) => (prev + 1) % slides.length);
  };

  const prevSlide = () => {
    setCurrentSlide((prev) => (prev - 1 + slides.length) % slides.length);
  };

  const goToSlide = (index: number) => {
    setCurrentSlide(index);
  };

  // Keyboard navigation
  useEffect(() => {
    const handleKeyDown = (e: KeyboardEvent) => {
      switch (e.key) {
        case 'ArrowRight':
        case ' ':
          e.preventDefault();
          setCurrentSlide((prev) => (prev + 1) % slides.length);
          break;
        case 'ArrowLeft':
          e.preventDefault();
          setCurrentSlide((prev) => (prev - 1 + slides.length) % slides.length);
          break;
        case 'p':
        case 'P':
          e.preventDefault();
          window.print();
          break;
      }
    };

    window.addEventListener('keydown', handleKeyDown);
    return () => window.removeEventListener('keydown', handleKeyDown);
  }, [slides.length]);

  return (
    <div className="h-screen w-full bg-gray-900 text-white overflow-hidden">
      {/* Progress bar */}
      <div className="h-1 w-full bg-gray-800">
        <div 
          className="h-full bg-blue-400 transition-all duration-300"
          style={{ width: `${((currentSlide + 1) / slides.length) * 100}%` }}
        />
      </div>

      {/* Slide content */}
      <div className="h-full relative">
        <Slide {...slides[currentSlide]} />
        
        {/* Navigation arrows */}
        <button
          onClick={prevSlide}
          className="absolute left-8 top-1/2 -translate-y-1/2 w-14 h-14 bg-white/90 backdrop-blur-sm border border-gray-300 rounded-full flex items-center justify-center shadow-lg hover:shadow-xl hover:bg-white transition-all z-10"
          aria-label="Previous slide"
        >
          <svg width="24" height="24" fill="currentColor" viewBox="0 0 24 24" className="text-gray-700">
            <path d="M15.41 16.58L10.83 12l4.58-4.58L14 6l-6 6 6 6z"/>
          </svg>
        </button>
        
        <button
          onClick={nextSlide}
          className="absolute right-8 top-1/2 -translate-y-1/2 w-14 h-14 bg-white/90 backdrop-blur-sm border border-gray-300 rounded-full flex items-center justify-center shadow-lg hover:shadow-xl hover:bg-white transition-all z-10"
          aria-label="Next slide"
        >
          <svg width="24" height="24" fill="currentColor" viewBox="0 0 24 24" className="text-gray-700">
            <path d="M8.59 16.58L13.17 12 8.59 7.42 10 6l6 6-6 6z"/>
          </svg>
        </button>

        {/* Slide indicators */}
        <div className="absolute bottom-8 left-1/2 -translate-x-1/2 flex gap-3 bg-black/60 px-6 py-3 rounded-full backdrop-blur-sm">
          {slides.map((_, index) => (
            <button
              key={index}
              onClick={() => goToSlide(index)}
              className={`w-3 h-3 rounded-full transition-all duration-300 ${
                index === currentSlide
                  ? 'bg-white scale-125 shadow-lg'
                  : 'bg-gray-400 hover:bg-gray-300 hover:scale-110'
              }`}
              aria-label={`Go to slide ${index + 1}`}
            />
          ))}
        </div>
      </div>

      {/* Status indicator */}
      <div className="fixed bottom-6 right-6 px-4 py-2 bg-black/60 backdrop-blur-sm text-white text-sm font-medium rounded-lg">
        {currentSlide + 1} / {slides.length}
      </div>
    </div>
  );
}
